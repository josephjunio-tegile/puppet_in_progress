=begin
#Tegile IntelliFlassh WEB API

#WEB API for managing Tegile IntelliFlash Arrays.

OpenAPI spec version: 2.2.0

Generated by: https://github.com/swagger-api/swagger-codegen.git
Swagger Codegen version: 2.3.0-SNAPSHOT

=end

require 'date'

module IFClient

  class BaseDataset_V2_1
    # Name of the project.
    attr_accessor :project_name

    # The pool in which the project exists.
    attr_accessor :pool_name

    # Indicates whether the project belongs to the current Tegile array.
    attr_accessor :local_dataset

    # Purpose of the dataset.
    attr_accessor :purpose

    # Compression algorithm, default value: \"lz4\"  
    attr_accessor :compression

    # Log compression, default value : \"off\" 
    attr_accessor :compressed_log

    # Deduplication setting, default value: \"on\" 
    attr_accessor :dedup

    # Number of data copies, default value: \"1\" 
    attr_accessor :copies

    # Primary cache specified, default value: \"all\" 
    attr_accessor :primary_cache

    # Secondary cache specified, default value: \"all\" 
    attr_accessor :secondary_cache

    # Read only flag, default value: \"off\" 
    attr_accessor :readonly

    # Prejudice in favor of log, default value: \"latency\" 
    attr_accessor :logbias

    # synchronization mode, default value: \"standard\"  
    attr_accessor :sync

    # This field is a string that uniquely identifies the volume on a Tegile array. A dataset path should have the format: PoolName/Local/ProjectName 
    attr_accessor :zfs_data_set_name

    attr_accessor :compression_class


    # Attribute mapping from ruby-style variable name to JSON key.
    def self.attribute_map
      {
        :'project_name' => :'projectName',
        :'pool_name' => :'poolName',
        :'local_dataset' => :'localDataset',
        :'purpose' => :'purpose',
        :'compression' => :'compression',
        :'compressed_log' => :'compressedLog',
        :'dedup' => :'dedup',
        :'copies' => :'copies',
        :'primary_cache' => :'primaryCache',
        :'secondary_cache' => :'secondaryCache',
        :'readonly' => :'readonly',
        :'logbias' => :'logbias',
        :'sync' => :'sync',
        :'zfs_data_set_name' => :'zfsDataSetName',
        :'compression_class' => :'compressionClass'
      }
    end

    # Attribute type mapping.
    def self.swagger_types
      {
        :'project_name' => :'String',
        :'pool_name' => :'String',
        :'local_dataset' => :'BOOLEAN',
        :'purpose' => :'String',
        :'compression' => :'String',
        :'compressed_log' => :'String',
        :'dedup' => :'String',
        :'copies' => :'String',
        :'primary_cache' => :'String',
        :'secondary_cache' => :'String',
        :'readonly' => :'String',
        :'logbias' => :'String',
        :'sync' => :'String',
        :'zfs_data_set_name' => :'String',
        :'compression_class' => :'BlockSize_enum'
      }
    end

    # Initializes the object
    # @param [Hash] attributes Model attributes in the form of hash
    def initialize(attributes = {})
      return unless attributes.is_a?(Hash)

      # convert string to symbol for hash key
      attributes = attributes.each_with_object({}){|(k,v), h| h[k.to_sym] = v}

      if attributes.has_key?(:'projectName')
        self.project_name = attributes[:'projectName']
      end

      if attributes.has_key?(:'poolName')
        self.pool_name = attributes[:'poolName']
      end

      if attributes.has_key?(:'localDataset')
        self.local_dataset = attributes[:'localDataset']
      end

      if attributes.has_key?(:'purpose')
        self.purpose = attributes[:'purpose']
      end

      if attributes.has_key?(:'compression')
        self.compression = attributes[:'compression']
      end

      if attributes.has_key?(:'compressedLog')
        self.compressed_log = attributes[:'compressedLog']
      end

      if attributes.has_key?(:'dedup')
        self.dedup = attributes[:'dedup']
      end

      if attributes.has_key?(:'copies')
        self.copies = attributes[:'copies']
      end

      if attributes.has_key?(:'primaryCache')
        self.primary_cache = attributes[:'primaryCache']
      end

      if attributes.has_key?(:'secondaryCache')
        self.secondary_cache = attributes[:'secondaryCache']
      end

      if attributes.has_key?(:'readonly')
        self.readonly = attributes[:'readonly']
      end

      if attributes.has_key?(:'logbias')
        self.logbias = attributes[:'logbias']
      end

      if attributes.has_key?(:'sync')
        self.sync = attributes[:'sync']
      end

      if attributes.has_key?(:'zfsDataSetName')
        self.zfs_data_set_name = attributes[:'zfsDataSetName']
      end

      if attributes.has_key?(:'compressionClass')
        self.compression_class = attributes[:'compressionClass']
      end

    end

    # Show invalid properties with the reasons. Usually used together with valid?
    # @return Array for valid properies with the reasons
    def list_invalid_properties
      invalid_properties = Array.new
      if @project_name.nil?
        invalid_properties.push("invalid value for 'project_name', project_name cannot be nil.")
      end

      if @pool_name.nil?
        invalid_properties.push("invalid value for 'pool_name', pool_name cannot be nil.")
      end

      if @local_dataset.nil?
        invalid_properties.push("invalid value for 'local_dataset', local_dataset cannot be nil.")
      end

      return invalid_properties
    end

    # Check to see if the all the properties in the model are valid
    # @return true if the model is valid
    def valid?
      return false if @project_name.nil?
      return false if @pool_name.nil?
      return false if @local_dataset.nil?
      return true
    end

    # Checks equality by comparing each attribute.
    # @param [Object] Object to be compared
    def ==(o)
      return true if self.equal?(o)
      self.class == o.class &&
          project_name == o.project_name &&
          pool_name == o.pool_name &&
          local_dataset == o.local_dataset &&
          purpose == o.purpose &&
          compression == o.compression &&
          compressed_log == o.compressed_log &&
          dedup == o.dedup &&
          copies == o.copies &&
          primary_cache == o.primary_cache &&
          secondary_cache == o.secondary_cache &&
          readonly == o.readonly &&
          logbias == o.logbias &&
          sync == o.sync &&
          zfs_data_set_name == o.zfs_data_set_name &&
          compression_class == o.compression_class
    end

    # @see the `==` method
    # @param [Object] Object to be compared
    def eql?(o)
      self == o
    end

    # Calculates hash code according to all attributes.
    # @return [Fixnum] Hash code
    def hash
      [project_name, pool_name, local_dataset, purpose, compression, compressed_log, dedup, copies, primary_cache, secondary_cache, readonly, logbias, sync, zfs_data_set_name, compression_class].hash
    end

    # Builds the object from hash
    # @param [Hash] attributes Model attributes in the form of hash
    # @return [Object] Returns the model itself
    def build_from_hash(attributes)
      return nil unless attributes.is_a?(Hash)
      self.class.swagger_types.each_pair do |key, type|
        if type =~ /\AArray<(.*)>/i
          # check to ensure the input is an array given that the the attribute
          # is documented as an array but the input is not
          if attributes[self.class.attribute_map[key]].is_a?(Array)
            self.send("#{key}=", attributes[self.class.attribute_map[key]].map{ |v| _deserialize($1, v) } )
          end
        elsif !attributes[self.class.attribute_map[key]].nil?
          self.send("#{key}=", _deserialize(type, attributes[self.class.attribute_map[key]]))
        end # or else data not found in attributes(hash), not an issue as the data can be optional
      end

      self
    end

    # Deserializes the data based on type
    # @param string type Data type
    # @param string value Value to be deserialized
    # @return [Object] Deserialized data
    def _deserialize(type, value)
      case type.to_sym
      when :DateTime
        DateTime.parse(value)
      when :Date
        Date.parse(value)
      when :String
        value.to_s
      when :Integer
        value.to_i
      when :Float
        value.to_f
      when :BOOLEAN
        if value.to_s =~ /\A(true|t|yes|y|1)\z/i
          true
        else
          false
        end
      when :Object
        # generic object (usually a Hash), return directly
        value
      when /\AArray<(?<inner_type>.+)>\z/
        inner_type = Regexp.last_match[:inner_type]
        value.map { |v| _deserialize(inner_type, v) }
      when /\AHash<(?<k_type>.+?), (?<v_type>.+)>\z/
        k_type = Regexp.last_match[:k_type]
        v_type = Regexp.last_match[:v_type]
        {}.tap do |hash|
          value.each do |k, v|
            hash[_deserialize(k_type, k)] = _deserialize(v_type, v)
          end
        end
      else # model
        temp_model = IFClient.const_get(type).new
        temp_model.build_from_hash(value)
      end
    end

    # Returns the string representation of the object
    # @return [String] String presentation of the object
    def to_s
      to_hash.to_s
    end

    # to_body is an alias to to_hash (backward compatibility)
    # @return [Hash] Returns the object in the form of hash
    def to_body
      to_hash
    end

    # Returns the object in the form of hash
    # @return [Hash] Returns the object in the form of hash
    def to_hash
      hash = {}
      self.class.attribute_map.each_pair do |attr, param|
        value = self.send(attr)
        next if value.nil?
        hash[param] = _to_hash(value)
      end
      hash
    end

    # Outputs non-array value in the form of hash
    # For object, use to_hash. Otherwise, just return the value
    # @param [Object] value Any valid value
    # @return [Hash] Returns the value in the form of hash
    def _to_hash(value)
      if value.is_a?(Array)
        value.compact.map{ |v| _to_hash(v) }
      elsif value.is_a?(Hash)
        {}.tap do |hash|
          value.each { |k, v| hash[k] = _to_hash(v) }
        end
      elsif value.respond_to? :to_hash
        value.to_hash
      else
        value
      end
    end

  end

end
